{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYyP8TETawIrFOBXBOFsxy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLesmes/cvSrc/blob/main/modern_cv_gen_ai/train_object_detection_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-om0GOdwmPNB"
      },
      "outputs": [],
      "source": [
        "!pip install keras-cv==0.6.1 keras-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "import keras_cv\n",
        "import numpy as np\n",
        "from keras_cv import bounding_box\n",
        "import os\n",
        "import resource\n",
        "from keras_cv import visualization\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "v_Oth1T5tJVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a dictionary pointing from int classes to class names\n",
        "classes = [\n",
        "    \"Aeroplane\",\n",
        "    \"Bicycle\",\n",
        "    \"Bird\",\n",
        "    \"Boat\",\n",
        "    \"Bottle\",\n",
        "    \"Bus\",\n",
        "    \"Car\",\n",
        "    \"Cat\",\n",
        "    \"Chair\",\n",
        "    \"Cow\",\n",
        "    \"Dining Table\",\n",
        "    \"Dog\",\n",
        "    \"Horse\",\n",
        "    \"Motorbike\",\n",
        "    \"Person\",\n",
        "    \"Potted Plant\",\n",
        "    \"Sheep\",\n",
        "    \"Sofa\",\n",
        "    \"Train\",\n",
        "    \"Tvmonitor\",\n",
        "    \"Total\",\n",
        "]\n",
        "\n",
        "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
      ],
      "metadata": {
        "id": "in2shdn9tJk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zoSZvVCYtJvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "\n",
        "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
        "    inputs = next(iter(inputs.take(1)))\n",
        "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
        "    visualization.plot_bounding_box_gallery(\n",
        "        images,\n",
        "        value_range=value_range,\n",
        "        rows=rows,\n",
        "        cols=cols,\n",
        "        y_true=bounding_boxes,\n",
        "        scale=5,\n",
        "        font_scale=0.7,\n",
        "        bounding_box_format=bounding_box_format,\n",
        "        class_mapping=class_mapping,\n",
        "    )"
      ],
      "metadata": {
        "id": "wXrpRY_ltblO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://keras.io/api/keras_cv/bounding_box/formats/#rel_xyxy-class\n",
        "def unpackage_raw_tfds_inputs(inputs, bounding_box_format):\n",
        "    image = inputs[\"image\"]\n",
        "    boxes = keras_cv.bounding_box.convert_format(\n",
        "        inputs[\"objects\"][\"bboxes\"],\n",
        "        images=image,\n",
        "        source=\"rel_xyxy\",\n",
        "        target=bounding_box_format,\n",
        "    )\n",
        "\n",
        "    bounding_boxes = {\n",
        "        \"classes\": tf.cast(inputs[\"objects\"][\"label\"], dtype=tf.float32),\n",
        "        \"boxes\": tf.cast(boxes, dtype=tf.float32),\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"images\": tf.cast(image, tf.float32),\n",
        "        \"bounding_boxes\": bounding_boxes,\n",
        "    }"
      ],
      "metadata": {
        "id": "iYvdgiPmtcEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pascal_voc(split, dataset, bounding_box_format):\n",
        "    ds = tfds.load(dataset, split=split, with_info=False, shuffle_files=True)\n",
        "    ds = ds.map(\n",
        "        lambda x: unpackage_raw_tfds_inputs(\n",
        "            x, bounding_box_format=bounding_box_format,\n",
        "            num_parallel_calls=tf.data.AUTOTUNE,\n",
        "        )\n",
        "    )\n",
        "    return ds"
      ],
      "metadata": {
        "id": "pEwXwNsctc4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = load_pascal_voc(\n",
        "    split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
        ")\n",
        "\n",
        "eval_ds = load_pascal_voc(\n",
        "    split=\"test\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
        ")\n",
        "\n",
        "train_ds = train_ds.shuffle(BATCH_SIZE * 4)"
      ],
      "metadata": {
        "id": "82CGOd2_tdGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use ragged batch since images can be of different sizes\n",
        "# and each image can have variable number of objects\n",
        "\n",
        "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "eval_ds = eval_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Visualize the dataset to ensure bounding boxes are in the right place\n",
        "# with correct labels. If done incorrectly, bounding boxes will not appear\n",
        "# or they will be in the wrong place.\n",
        "\n",
        "visualize_dataset(\n",
        "    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
        ")"
      ],
      "metadata": {
        "id": "_Xn_wuyCtdQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize validation set\n",
        "visualize_dataset(\n",
        "    eval_ds,\n",
        "    bounding_box_format=\"xywh\",\n",
        "    value_range=(0, 255),\n",
        "    rows=2,\n",
        "    cols=2,\n",
        ")"
      ],
      "metadata": {
        "id": "Gu789Ouutdqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation is complex since after the image is modified, the bounding\n",
        "# boxes must also be modified accordingly!\n",
        "\n",
        "augmenter = keras.Sequential(\n",
        "    layers=[\n",
        "        keras_cv.layers.RandomFlip(\n",
        "            mode=\"horizontal\",\n",
        "            bounding_box_format=\"xywh\",\n",
        "        ),\n",
        "        keras_cv.layers.JitteredResize(\n",
        "            target_size=(640, 640),\n",
        "            scale_factor=(0.75, 1.3),\n",
        "            bounding_box_format=\"xywh\",\n",
        "        ),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "eUGmpRDRtd93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "visualize_dataset(\n",
        "    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
        ")"
      ],
      "metadata": {
        "id": "3VcSkk9UteLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use deterministic resizing for the validation set\n",
        "inference_resizing = keras_cv.layers.Resizing(\n",
        "    640, 640, bounding_box_format=\"xywh\", pad_to_aspect_ratio=True\n",
        ")\n",
        "eval_ds = eval_ds.map(inference_resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Let's make sure the resizing worked\n",
        "visualize_dataset(\n",
        "    eval_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
        ")"
      ],
      "metadata": {
        "id": "ElIZkoQExPtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the final form our model expects:\n",
        "# tuple of (images, bounding_box_dictionary)\n",
        "# to_dense() makes the batch compatible with TPU\n",
        "\n",
        "def dict_to_tuple(inputs):\n",
        "    return inputs[\"images\"], bounding_box.to_dense(\n",
        "        inputs[\"bounding_boxes\"], max_boxes=32\n",
        "    )\n",
        "\n",
        "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "eval_ds = eval_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "eval_ds = eval_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "UU9UeZB3xRON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_lr = 0.005\n",
        "# including a global_clipnorm is extremely important in object detection tasks\n",
        "optimizer = tf.keras.optimizers.SGD(\n",
        "    learning_rate=base_lr, momentum=0.9, global_clipnorm=10.0\n",
        ")\n",
        "\n",
        "# Creates a \"RetinaNet\" from ResNet50 backbone\n",
        "model = keras_cv.models.RetinaNet.from_preset(\n",
        "    \"resnet50_imagenet\",\n",
        "    num_classes=len(class_mapping),\n",
        "    bounding_box_format=\"xywh\",\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    classification_loss=\"focal\",\n",
        "    box_loss=\"smoothl1\",\n",
        "    optimizer=optimizer,\n",
        ")"
      ],
      "metadata": {
        "id": "10bRL7AwxTLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove take(20) for full training (takes very long!)\n",
        "model.fit(\n",
        "    train_ds.take(20),\n",
        "    validation_data=eval_ds.take(20),\n",
        "    epochs=10,\n",
        ")\n",
        "\n",
        "# Let's load a fully trained model to test predictions\n",
        "model = keras_cv.models.RetinaNet.from_preset(\n",
        "    \"retinanet_resnet50_pascalvoc\", bounding_box_format=\"xywh\"\n",
        ")\n",
        "\n",
        "# construct a dataset with larger batches:\n",
        "visualization_ds = eval_ds.unbatch()\n",
        "visualization_ds = visualization_ds.ragged_batch(16)\n",
        "visualization_ds = visualization_ds.shuffle(8)"
      ],
      "metadata": {
        "id": "3hBpOUjixWPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_detections(model, dataset, bounding_box_format):\n",
        "    images, y_true = next(iter(dataset.take(1)))\n",
        "    y_pred = model.predict(images)\n",
        "    y_pred = bounding_box.to_ragged(y_pred)\n",
        "    visualization.plot_bounding_box_gallery(\n",
        "        images,\n",
        "        value_range=(0, 255),\n",
        "        bounding_box_format=bounding_box_format,\n",
        "        y_true=y_true,\n",
        "        y_pred=y_pred,\n",
        "        scale=4,\n",
        "        rows=2,\n",
        "        cols=4,\n",
        "        show=True,\n",
        "        font_scale=0.7,\n",
        "        class_mapping=class_mapping,\n",
        "    )"
      ],
      "metadata": {
        "id": "KI3lx19Dx3qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***To be clear, this model already has a prediction decoder! This is just showing you how to set parameters yourself.***"
      ],
      "metadata": {
        "id": "I3WWtHGMx9It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set IoU and confidence threshold\n",
        "model.prediction_decoder = keras_cv.layers.MultiClassNonMaxSuppression(\n",
        "    bounding_box_format=\"xywh\",\n",
        "    from_logits=True,\n",
        "    iou_threshold=0.5,\n",
        "    confidence_threshold=0.75,\n",
        ")\n",
        "\n",
        "visualize_detections(model, dataset=visualization_ds, bounding_box_format=\"xywh\")"
      ],
      "metadata": {
        "id": "5IPLGvHTx5GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypYfDfyCyDPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}